{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from Utilities import config\n",
    "from Utilities.model import YOLOv3\n",
    "from Utilities.transforms import test_transforms\n",
    "from Utilities.utils import cells_to_bboxes, non_max_suppression, plot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv3.load_from_checkpoint( \"Store/epoch=39-step=16560.ckpt\", map_location=torch.device(\"cpu\"))\n",
    "# model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv3(\n",
       "  (layers): ModuleList(\n",
       "    (0): CNNBlock(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): CNNBlock(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CNNBlock(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): CNNBlock(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): CNNBlock(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (10): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): CNNBlock(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (12): CNNBlock(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): CNNBlock(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (15): ScalePrediction(\n",
       "      (pred): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (leaky): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(1024, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (leaky): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): CNNBlock(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (17): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (18): CNNBlock(\n",
       "      (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (19): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (20): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): CNNBlock(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (22): ScalePrediction(\n",
       "      (pred): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (leaky): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(512, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (leaky): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): CNNBlock(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (24): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (25): CNNBlock(\n",
       "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (26): CNNBlock(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (27): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): CNNBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "          (1): CNNBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (28): CNNBlock(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (29): ScalePrediction(\n",
       "      (pred): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (leaky): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (leaky): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLOv3(num_classes=config.NUM_CLASSES)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"Store/yolov3.pth\", map_location=torch.device(\"cpu\")))\n",
    "model.load_from_checkpoint(\n",
    "    \"Store/epoch=39-step=16560.ckpt\", map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScalePrediction(\n",
       "  (pred): Sequential(\n",
       "    (0): CNNBlock(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): CNNBlock(\n",
       "      (conv): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Store/yolov3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox(input_img, thresh=0.5, iou_thresh=0.6, anchors=model.scaled_anchors):\n",
    "    input_img = test_transforms(image=input_img)[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(input_img)\n",
    "        # bboxes = [[] for _ in range(input_img.shape[0])]\n",
    "        # bboxes = []\n",
    "        for i in range(3):\n",
    "            batch_size, A, S, _, _ = out[i].shape\n",
    "            anchor = anchors[i]\n",
    "            boxes_scale_i = cells_to_bboxes(out[i], anchor, S=S, is_preds=True)\n",
    "            bboxes = boxes_scale_i[0]\n",
    "            # for idx, (box) in enumerate(boxes_scale_i):\n",
    "            #     bboxes[idx] += box\n",
    "\n",
    "    # for i in range(batch_size // 4):\n",
    "    nms_boxes = non_max_suppression(\n",
    "        bboxes,\n",
    "        iou_threshold=iou_thresh,\n",
    "        threshold=thresh,\n",
    "        box_format=\"midpoint\",\n",
    "    )\n",
    "    fig = plot_image(input_img[0].permute(1, 2, 0).detach().cpu(), nms_boxes)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_0 = model(torch.zeros(1, 3, 416, 416))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out_0[out_0\u001b[39m.\u001b[39;49margmax(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 19 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "out_0[out_0.argmax(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 13, 13, 25])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m highest_score_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(reshaped_out[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Gather the 25 elements from the last dimension based on the highest score indices\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m highest_score_elements \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mgather(reshaped_out, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, index\u001b[39m=\u001b[39;49mhighest_score_indices\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     13\u001b[0m \u001b[39m# The shape of highest_score_elements will be (1, 3, 13, 13, 1, 25), so squeeze to remove the extra dimension\u001b[39;00m\n\u001b[1;32m     14\u001b[0m highest_score_elements \u001b[39m=\u001b[39m highest_score_elements\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "# Assuming 'out' is your tensor of size (1, 3, 13, 13, 25)\n",
    "# and you want to get the 25 elements for the highest score for each (1, 3, 13, 13) element\n",
    "\n",
    "# Reshape the tensor to collapse the last two dimensions\n",
    "reshaped_out = out_0.view(1, 3, 13, 13, -1)\n",
    "\n",
    "# Get the highest score index (0th index) along the last dimension\n",
    "highest_score_indices = torch.argmax(reshaped_out[..., 0], dim=-1)\n",
    "\n",
    "# Gather the 25 elements from the last dimension based on the highest score indices\n",
    "highest_score_elements = torch.gather(reshaped_out, dim=-1, index=highest_score_indices.unsqueeze(-1))\n",
    "\n",
    "# The shape of highest_score_elements will be (1, 3, 13, 13, 1, 25), so squeeze to remove the extra dimension\n",
    "highest_score_elements = highest_score_elements.squeeze(-2)\n",
    "\n",
    "# Now highest_score_elements contains the 25 elements for the highest score for each (1, 3, 13, 13) element\n",
    "print(highest_score_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract objectness scores\n",
    "objectness_scores = out_0[..., 0]\n",
    "\n",
    "# Step 2: Get the index of the highest objectness score\n",
    "max_score_index = torch.argmax(objectness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 25 elements in the last dimension for the corresponding index\n",
    "selected_elements = out_0[0, :, max_score_index // 13, max_score_index % 13, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_elements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'dim' must be int, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49margmax(out_0, dim\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m))\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'dim' must be int, not tuple"
     ]
    }
   ],
   "source": [
    "torch.argmax(out_0, dim=(1,2,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_obj_arg = objectness_scores.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_obj_arg_onehot = torch.zeros(objectness_scores.flatten().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_obj_arg_onehot[max_obj_arg] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_obj_arg_onehot = max_obj_arg_onehot.reshape_as(objectness_scores,).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 13, 13])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_obj_arg_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_elements = out_0[max_obj_arg_onehot==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1751,  0.1118,  1.0949, -0.7356, -0.8127, -3.3133,  1.3863, -1.5563,\n",
       "          0.0267,  1.3461, -2.8634, -0.6618, -1.9784, -1.4624, -3.6695, -3.3399,\n",
       "         -2.9955, -1.8513,  1.0410,  3.3047,  3.7847, -3.9926, -4.6339, -0.9043,\n",
       "         -1.7867]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_objectness_class_preds(model, input_img):\n",
    "    out = model(input_img)[-1]\n",
    "    \n",
    "    # Step 1: Extract objectness scores\n",
    "    objectness_scores = out[..., 0]\n",
    "\n",
    "    # Step 2: Get the index of the highest objectness score\n",
    "    max_obj_arg = torch.argmax(objectness_scores)\n",
    "\n",
    "    max_obj_arg_onehot = torch.zeros(objectness_scores.flatten().shape[0])\n",
    "    max_obj_arg_onehot[max_obj_arg] = 1\n",
    "\n",
    "    max_obj_arg_onehot = max_obj_arg_onehot.reshape_as(objectness_scores,).int()    \n",
    "\n",
    "    selected_elements = out[max_obj_arg_onehot==1]\n",
    "    selected_elements = selected_elements[:, 5:]\n",
    "\n",
    "    return selected_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_top_objectness_class_preds(model, torch.zeros(1, 3, 416, 416)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "input_img = torch.zeros(1, 3, 416, 416)\n",
    "org_img = input_img\n",
    "\n",
    "def return_top_objectness_class_preds(model, input_img):\n",
    "    out = model(input_img)[0]\n",
    "\n",
    "    # Step 1: Extract objectness scores\n",
    "    objectness_scores = out[..., 0]\n",
    "\n",
    "    # Step 2: Get the index of the highest objectness score\n",
    "    max_obj_arg = torch.argmax(objectness_scores)\n",
    "\n",
    "    max_obj_arg_onehot = torch.zeros(objectness_scores.flatten().shape[0])\n",
    "    max_obj_arg_onehot[max_obj_arg] = 1\n",
    "\n",
    "    max_obj_arg_onehot = max_obj_arg_onehot.reshape_as(\n",
    "        objectness_scores,\n",
    "    ).int()\n",
    "\n",
    "    selected_elements = out[max_obj_arg_onehot == 1]\n",
    "    selected_elements = selected_elements[:, 5:]\n",
    "\n",
    "    return selected_elements\n",
    "\n",
    "\n",
    "class TopObjectnessClassPreds(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return return_top_objectness_class_preds(self.model, x)\n",
    "\n",
    "\n",
    "TopObjectnessClassPredsObj = TopObjectnessClassPreds(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNBlock(\n",
       "  (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (leaky): LeakyReLU(negative_slope=0.1)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mlayers\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_grad_cam\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m show_cam_on_image\n\u001b[1;32m      4\u001b[0m cam \u001b[39m=\u001b[39m GradCAM(\n\u001b[1;32m      5\u001b[0m         model\u001b[39m=\u001b[39mTopObjectnessClassPredsObj,\n\u001b[1;32m      6\u001b[0m         target_layers\u001b[39m=\u001b[39m[model\u001b[39m.\u001b[39mlayers[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]],\n\u001b[1;32m      7\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m grayscale_cam \u001b[39m=\u001b[39m cam(input_tensor\u001b[39m=\u001b[39;49minput_img, targets\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m      9\u001b[0m grayscale_cam \u001b[39m=\u001b[39m grayscale_cam[\u001b[39m0\u001b[39m, :]\n\u001b[1;32m     11\u001b[0m visualization \u001b[39m=\u001b[39m show_cam_on_image(\n\u001b[1;32m     12\u001b[0m     org_img \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m,\n\u001b[1;32m     13\u001b[0m     grayscale_cam,\n\u001b[1;32m     14\u001b[0m     use_rgb\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     image_weight\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/pytorch_grad_cam/base_cam.py:188\u001b[0m, in \u001b[0;36mBaseCAM.__call__\u001b[0;34m(self, input_tensor, targets, aug_smooth, eigen_smooth)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m aug_smooth \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_augmentation_smoothing(\n\u001b[1;32m    186\u001b[0m         input_tensor, targets, eigen_smooth)\n\u001b[0;32m--> 188\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(input_tensor,\n\u001b[1;32m    189\u001b[0m                     targets, eigen_smooth)\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/pytorch_grad_cam/base_cam.py:95\u001b[0m, in \u001b[0;36mBaseCAM.forward\u001b[0;34m(self, input_tensor, targets, eigen_smooth)\u001b[0m\n\u001b[1;32m     84\u001b[0m     loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m \u001b[39m# In most of the saliency attribution papers, the saliency is\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39m# computed with a single target layer.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m# Commonly it is the last convolutional layer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m# use all conv layers for example, all Batchnorm layers,\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# or something else.\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m cam_per_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_cam_per_layer(input_tensor,\n\u001b[1;32m     96\u001b[0m                                            targets,\n\u001b[1;32m     97\u001b[0m                                            eigen_smooth)\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_multi_layers(cam_per_layer)\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/pytorch_grad_cam/base_cam.py:127\u001b[0m, in \u001b[0;36mBaseCAM.compute_cam_per_layer\u001b[0;34m(self, input_tensor, targets, eigen_smooth)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(grads_list):\n\u001b[1;32m    125\u001b[0m     layer_grads \u001b[39m=\u001b[39m grads_list[i]\n\u001b[0;32m--> 127\u001b[0m cam \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_cam_image(input_tensor,\n\u001b[1;32m    128\u001b[0m                          target_layer,\n\u001b[1;32m    129\u001b[0m                          targets,\n\u001b[1;32m    130\u001b[0m                          layer_activations,\n\u001b[1;32m    131\u001b[0m                          layer_grads,\n\u001b[1;32m    132\u001b[0m                          eigen_smooth)\n\u001b[1;32m    133\u001b[0m cam \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(cam, \u001b[39m0\u001b[39m)\n\u001b[1;32m    134\u001b[0m scaled \u001b[39m=\u001b[39m scale_cam_image(cam, target_size)\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/pytorch_grad_cam/base_cam.py:50\u001b[0m, in \u001b[0;36mBaseCAM.get_cam_image\u001b[0;34m(self, input_tensor, target_layer, targets, activations, grads, eigen_smooth)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cam_image\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     43\u001b[0m                   input_tensor: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m     44\u001b[0m                   target_layer: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m                   grads: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m     48\u001b[0m                   eigen_smooth: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m---> 50\u001b[0m     weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_cam_weights(input_tensor,\n\u001b[1;32m     51\u001b[0m                                    target_layer,\n\u001b[1;32m     52\u001b[0m                                    targets,\n\u001b[1;32m     53\u001b[0m                                    activations,\n\u001b[1;32m     54\u001b[0m                                    grads)\n\u001b[1;32m     55\u001b[0m     weighted_activations \u001b[39m=\u001b[39m weights[:, :, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m activations\n\u001b[1;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m eigen_smooth:\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/pytorch_grad_cam/grad_cam.py:22\u001b[0m, in \u001b[0;36mGradCAM.get_cam_weights\u001b[0;34m(self, input_tensor, target_layer, target_category, activations, grads)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cam_weights\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     17\u001b[0m                     input_tensor,\n\u001b[1;32m     18\u001b[0m                     target_layer,\n\u001b[1;32m     19\u001b[0m                     target_category,\n\u001b[1;32m     20\u001b[0m                     activations,\n\u001b[1;32m     21\u001b[0m                     grads):\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mmean(grads, axis\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3464\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3462\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 3464\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39;49m_mean(a, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   3465\u001b[0m                       out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/numpy/core/_methods.py:169\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    165\u001b[0m arr \u001b[39m=\u001b[39m asanyarray(a)\n\u001b[1;32m    167\u001b[0m is_float16_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m rcount \u001b[39m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[39m=\u001b[39;49mkeepdims, where\u001b[39m=\u001b[39;49mwhere)\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m rcount \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m where \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m umr_any(rcount \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    171\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mMean of empty slice.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mRuntimeWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/WorkProjects/ERA-v1/ERAenv/lib/python3.10/site-packages/numpy/core/_methods.py:77\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     75\u001b[0m     items \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     76\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m axis:\n\u001b[0;32m---> 77\u001b[0m         items \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mshape[mu\u001b[39m.\u001b[39;49mnormalize_axis_index(ax, arr\u001b[39m.\u001b[39;49mndim)]\n\u001b[1;32m     78\u001b[0m     items \u001b[39m=\u001b[39m nt\u001b[39m.\u001b[39mintp(items)\n\u001b[1;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[39m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[39m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m     \u001b[39m# guarded to protect circular imports\u001b[39;00m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "cam = GradCAM(\n",
    "        model=TopObjectnessClassPredsObj,\n",
    "        target_layers=[model.layers[-1]],\n",
    "    )\n",
    "grayscale_cam = cam(input_tensor=input_img, targets=None)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "visualization = show_cam_on_image(\n",
    "    org_img / 255,\n",
    "    grayscale_cam,\n",
    "    use_rgb=True,\n",
    "    image_weight=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScalePrediction(\n",
       "  (pred): Sequential(\n",
       "    (0): CNNBlock(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): CNNBlock(\n",
       "      (conv): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred\n"
     ]
    }
   ],
   "source": [
    "for child in model.layers[-1].named_children():\n",
    "    print(child[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pred'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.layers[-1].named_children())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "22\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for layer_idx, layer in enumerate(model.layers):\n",
    "    try:\n",
    "        if next(layer.named_children())[0] == 'pred':\n",
    "            print(layer_idx)\n",
    "            # print(layer)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScalePrediction(\n",
       "  (pred): Sequential(\n",
       "    (0): CNNBlock(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): CNNBlock(\n",
       "      (conv): Conv2d(1024, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScalePrediction(\n",
       "  (pred): Sequential(\n",
       "    (0): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): CNNBlock(\n",
       "      (conv): Conv2d(512, 75, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
